{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Stock Market Sentiment with LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "\n",
    "pd.set_option('max_colwidth', 800)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/siddharth/workspace-python/LSTM_stock_market_sentiment'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data\n",
    "\n",
    "\n",
    "Data used here is from **StockTwits.com** which is a social media network for traders and investors to share their views about the stock market. When a user posts a message, they tag the relevant stock ticker [$SPY in our case which is for S&P 500 index fund] and have option to tag the message with their sentiment - \"bullish\" or \"bearish\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv file\n",
    "data = pd.read_csv('StockTwits_SPY_Sentiment_2017.gz',encoding='utf-8',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$SPY crazy day so far!</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$SPY Will make a new ATH this week. Watch it!</td>\n",
       "      <td>bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$SPY $DJIA white elephant in room is $AAPL. Up 14% since election. Strong headwinds w/Trump trade &amp; Strong dollar. How many 7's do you see?</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$SPY blocks above. We break above them We should push to double top</td>\n",
       "      <td>bullish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$SPY Nothing happening in the market today, guess I'll go to the store and spend some $.</td>\n",
       "      <td>bearish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       message  \\\n",
       "0                                                                                                                       $SPY crazy day so far!   \n",
       "1                                                                                                $SPY Will make a new ATH this week. Watch it!   \n",
       "2  $SPY $DJIA white elephant in room is $AAPL. Up 14% since election. Strong headwinds w/Trump trade & Strong dollar. How many 7's do you see?   \n",
       "3                                                                          $SPY blocks above. We break above them We should push to double top   \n",
       "4                                                     $SPY Nothing happening in the market today, guess I'll go to the store and spend some $.   \n",
       "\n",
       "  sentiment  \n",
       "0   bearish  \n",
       "1   bullish  \n",
       "2   bearish  \n",
       "3   bullish  \n",
       "4   bearish  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess messages\n",
    "\n",
    "Preprocessing the raw text data to normalize for the context. Normalizing for known unique 'entities' that carry similar contextual meaning. \n",
    "\n",
    "Therefore replacing the references to \n",
    "* specific stock ticker ($SPY), \n",
    "* user names, \n",
    "* url links,\n",
    "* numbers with special tokenidentifying the entity \n",
    "\n",
    "Converting text into lower case and removing punctuations.               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_messages(text):\n",
    "    \n",
    "    \n",
    "    # SAVING REGEX PATTERNS\n",
    "    REGEX_PRICE_SIGN = re.compile(r'\\$(?!\\d*\\.?\\d+%)\\d*\\.?\\d+|(?!\\d*\\.?\\d+%)\\d*\\.?\\d+\\$')\n",
    "    REGEX_PRICE_NOSIGN = re.compile(r'(?!\\d*\\.?\\d+%)(?!\\d*\\.?\\d+k)\\d*\\.?\\d+')\n",
    "    REGEX_TICKER = re.compile('\\$[a-zA-Z]+')\n",
    "    REGEX_USER = re.compile('\\@\\w+')\n",
    "    REGEX_LINK = re.compile('https?:\\/\\/[^\\s]+')\n",
    "    REGEX_HTML_ENTITY = re.compile('\\&\\w+')\n",
    "    REGEX_NON_ACSII = re.compile('[^\\x00-\\x7f]')\n",
    "    \n",
    "    #string.punctuation - '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    #string.punctuation.replace('<', '').replace('>', '')\n",
    "    #--> '!\"#$%&\\'()*+,-./:;=?@[\\\\]^_`{|}~'\n",
    "    #re.escape(string.punctuation.replace('<', ''))\n",
    "    #--> '\\\\!\\\\\"\\\\#\\\\$\\\\%\\\\&\\\\\\'\\\\(\\\\)\\\\*\\\\+\\\\,\\\\-\\\\.\\\\/\\\\:\\\\;\\\\=\\\\>\\\\?\\\\@\\\\[\\\\\\\\\\\\]\\\\^_\\\\`\\\\{\\\\|\\\\}\\\\~'\n",
    "    \n",
    "    REGEX_PUNCTUATION = re.compile('[%s]' % re.escape(string.punctuation.replace('<', '').replace('>', '')))\n",
    "    REGEX_NUMBER = re.compile(r'[-+]?[0-9]+')\n",
    "    \n",
    "    \n",
    "    # CONVERTING TO LOWERCASE\n",
    "    text = text.lower()\n",
    "    \n",
    "    # REPLACE ST \"ENTITITES\" WITH A UNIQUE TOKEN\n",
    "    text = re.sub(REGEX_TICKER, ' <TICKER> ', text)\n",
    "    text = re.sub(REGEX_USER, ' <USER> ', text)\n",
    "    text = re.sub(REGEX_LINK, ' <LINK> ', text)\n",
    "    text = re.sub(REGEX_PRICE_SIGN, ' <PRICE> ', text)\n",
    "    text = re.sub(REGEX_PRICE_NOSIGN, ' <NUMBER> ', text)\n",
    "    text = re.sub(REGEX_NUMBER, ' <NUMBER> ', text)\n",
    "    # REMOVE EXTRANEOUS TEXT DATA\n",
    "    text = re.sub(REGEX_HTML_ENTITY, \"\", text)\n",
    "    text = re.sub(REGEX_NON_ACSII, \"\", text)\n",
    "    text = re.sub(REGEX_PUNCTUATION, \"\", text)\n",
    "    \n",
    "    # Tokenizing and removing < and > that are not in special tokens\n",
    "    words = \" \".join(token.replace(\"<\", \"\").replace(\">\", \"\")\n",
    "                     if token not in ['<TICKER>', '<USER>', '<LINK>', '<PRICE>', '<NUMBER>']\n",
    "                     else token\n",
    "                     for token in text.split())\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = np.array([preprocess_messages(msg) for msg in data.message.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
